{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the COCO results file\n",
    "\n",
    "This notebook show how to generate a a json file containing the results of the prediction with a chosen model on a chosen data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone ODIN EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = input(\"Digit your user name:\")\n",
    "PASSWORD = getpass(\"Digit your password:\")\n",
    "\n",
    "if os.getcwd().endswith(\"yaep\"):\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "!rm -rf data efficientdet yaep\n",
    "!git clone https://$USERNAME:$PASSWORD@bitbucket.springlab.enel.com/scm/ipodin/efficientdet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Yet-Another-EfficientDet-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"http_proxy\"] = \"http://proxy-euc1.enelint.global:8080\"\n",
    "os.environ[\"https_proxy\"] = \"https://proxy-euc1.enelint.global:8080\"\n",
    "os.environ[\"no_proxy\"] = \"169.254.169.254,169.254.170.2\"\n",
    "\n",
    "!pip install pycocotools\n",
    "!pip install webcolors\n",
    "\n",
    "!git clone https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch.git yaep\n",
    "os.chdir(\"./yaep\")\n",
    "\n",
    "# add prepare_data and coco_eval to yaep\n",
    "!cp ../efficientdet/prepare_data.py .\n",
    "!cp ../efficientdet/coco_eval.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following paths\n",
    "EVAL_SET = \"val\"\n",
    "MODEL_NAME = \"your-model-name\"  # e.g. element_detector\n",
    "S3_DATA_PATH = \"s3://your/s3/data/path\"  # e.g. f\"s3://enel-noprod-glin-ap35001-odin1/training/datasets/your-dataset/{EVAL_SET}/\"\n",
    "S3_MODEL_PATH = \"s3://your/s3/model/path\"  # e.g. \"s3://enel-noprod-glin-ap35001-odin1/[...]/output/model.tar.gz\"\n",
    "S3_ANNOTATIONS_PATH = \"s3://your/s3/annotations/path\"  # e.g.  f\"s3://enel-noprod-glin-ap35001-odin1/training/datasets/your-dataset/annotations/instances_{EVAL_SET}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = f\"../data\"\n",
    "LOCAL_IMGS_DIR = f\"{LOCAL_DATA_DIR}/{EVAL_SET}\"\n",
    "LOCAL_ANNOTATIONS_PATH = f\"../data/annotations/instances_{EVAL_SET}.json\"\n",
    "LOCAL_MODEL_DIR = f\"../model/{MODEL_NAME}\"\n",
    "\n",
    "model_path = f\"{LOCAL_MODEL_DIR}/model.pth\"\n",
    "hps_path = f\"{LOCAL_MODEL_DIR}/hyperparameters.yml\"\n",
    "!mkdir -p {LOCAL_MODEL_DIR}\n",
    "!aws s3 cp {S3_DATA_PATH} {LOCAL_IMGS_DIR} --recursive --quiet\n",
    "!aws s3 cp {S3_ANNOTATIONS_PATH} {LOCAL_ANNOTATIONS_PATH}\n",
    "!aws s3 cp {S3_MODEL_PATH} ../\n",
    "!tar -xf ../model.tar.gz -C {LOCAL_MODEL_DIR}\n",
    "\n",
    "# manage old formats\n",
    "shutil.move(glob.glob(os.path.join(LOCAL_MODEL_DIR, \"*.yml\"))[0], hps_path)\n",
    "shutil.move(glob.glob(os.path.join(LOCAL_MODEL_DIR, \"*.pth\"))[0], model_path)\n",
    "\n",
    "# load hyperparameters\n",
    "with open(hps_path) as f:\n",
    "        hps = yaml.load(f, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data import prepare_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"CATENA SPINTEROMETRICA\",\n",
    "    \"FONDAZIONE AFFIORANTE\",\n",
    "    \"IMS\",\n",
    "    \"ISOLATORE RIGIDO\",\n",
    "    \"ISOLATORE SOSPESO\",\n",
    "    \"PASSAGGIO AEREO-CAVO\",\n",
    "    \"SCARICATORE DISTACCO\",\n",
    "    \"SCARICATORE SU CATENA IRRIGIDITA\",\n",
    "    \"SEZIONATORE TRIPOLARE ORIZZONTALE\",\n",
    "    \"SEZIONATORE TRIPOLARE VERTICALE\",\n",
    "    \"SEZIONATORE UNIPOLARE\",\n",
    "    \"SOSTEGNO A TRALICCIO\",\n",
    "    \"SOSTEGNO TUBOLARE\",\n",
    "    \"TRASFORMATORE\"\n",
    "]\n",
    "\n",
    "prepare_annotations(LOCAL_DATA_DIR, CLASSES, [EVAL_SET])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set `generate_res_file()` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following parameters according to your problem (if necessary)\n",
    "THRESHOLD = 0.05  \n",
    "NMS_THRESHOLD = 0.95\n",
    "MAX_IMGS = 10000  \n",
    "USE_FLOAT16 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `generate_res_file()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco_eval import generate_res_file\n",
    "\n",
    "\n",
    "res_file = os.path.join(\n",
    "    LOCAL_MODEL_DIR,\n",
    "    f\"coco_res_{EVAL_SET}_th_{THRESHOLD}_nms_th_{NMS_THRESHOLD}\"\n",
    "    f\"_f16_{str(USE_FLOAT16).lower()}.json\",\n",
    ")\n",
    "\n",
    "_ = generate_res_file(\n",
    "    imgs_dir=LOCAL_IMGS_DIR, \n",
    "    model_dir=LOCAL_MODEL_DIR, \n",
    "    annotation_file=LOCAL_ANNOTATIONS_PATH, \n",
    "    res_file=res_file, \n",
    "    max_size=(512, 640, 768, 896, 1024, 1280, 1280, 1536)[hps[\"compound_coef\"]], \n",
    "    eval_set=EVAL_SET, \n",
    "    threshold=THRESHOLD, \n",
    "    nms_threshold=NMS_THRESHOLD, \n",
    "    max_imgs=MAX_IMGS, \n",
    "    use_float16=USE_FLOAT16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
